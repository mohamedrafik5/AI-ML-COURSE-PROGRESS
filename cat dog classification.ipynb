{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabec8d9-4bf3-43bb-aa5c-a41308fd8e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\asus\\anaconda3\\envs\\rafikdl\\lib\\site-packages (from scipy) (1.26.0)\n",
      "1.15.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import pandas as pd\n",
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install scipy\n",
    "import scipy\n",
    "print(scipy.__version__)\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcef3d04-c443-4dc8-88fc-ffac409523d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a177e832-3183-418b-b4f2-c0069cc886a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'D:\\cat dog clasi\\cat dog dataset',\n",
    "    target_size=(64,64),     # smaller size for ANN\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    r'D:\\cat dog clasi\\cat dog dataset',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ecb5fa-f8ff-490a-88ca-5d624ce7ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(64,64,3)),  # Flatten image to 1D vector\n",
    "    Dense(128, activation='relu'),Dropout(0.5),\n",
    "    Dense(64, activation='relu',kernel_regularizer=l2(0.001)),\n",
    "    Dense(1, activation='sigmoid')   # binary output (cat or dog)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5537f4-f74b-4c4c-b887-f4618d72d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 5s 156ms/step - loss: 1.8125 - accuracy: 0.5163 - mae: 0.4880 - mse: 0.3849 - val_loss: 0.8135 - val_accuracy: 0.4950 - val_mae: 0.5054 - val_mse: 0.2712\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.9549 - accuracy: 0.4988 - mae: 0.5016 - mse: 0.3126 - val_loss: 0.7553 - val_accuracy: 0.5450 - val_mae: 0.4977 - val_mse: 0.2485\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.7950 - accuracy: 0.4863 - mae: 0.5005 - mse: 0.2672 - val_loss: 0.7514 - val_accuracy: 0.4900 - val_mae: 0.4988 - val_mse: 0.2499\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 3s 130ms/step - loss: 0.7516 - accuracy: 0.5025 - mae: 0.4977 - mse: 0.2512 - val_loss: 0.7530 - val_accuracy: 0.5000 - val_mae: 0.5001 - val_mse: 0.2533\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.7456 - accuracy: 0.5013 - mae: 0.4991 - mse: 0.2505 - val_loss: 0.7418 - val_accuracy: 0.5050 - val_mae: 0.4995 - val_mse: 0.2496\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 3s 122ms/step - loss: 0.7415 - accuracy: 0.5125 - mae: 0.4997 - mse: 0.2502 - val_loss: 0.7400 - val_accuracy: 0.4850 - val_mae: 0.5001 - val_mse: 0.2502\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.7382 - accuracy: 0.5188 - mae: 0.4998 - mse: 0.2498 - val_loss: 0.7376 - val_accuracy: 0.5050 - val_mae: 0.5001 - val_mse: 0.2501\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.7364 - accuracy: 0.5063 - mae: 0.4993 - mse: 0.2499 - val_loss: 0.7358 - val_accuracy: 0.5000 - val_mae: 0.5000 - val_mse: 0.2501\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.7332 - accuracy: 0.5425 - mae: 0.4991 - mse: 0.2492 - val_loss: 0.7325 - val_accuracy: 0.5450 - val_mae: 0.4991 - val_mse: 0.2492\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.7314 - accuracy: 0.5213 - mae: 0.4986 - mse: 0.2490 - val_loss: 0.7317 - val_accuracy: 0.4850 - val_mae: 0.4991 - val_mse: 0.2494\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "             tf.keras.metrics.MeanSquaredError(name=\"mse\")]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807008f9-386d-4445-b121-fe78f80a097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 101ms/step - loss: 0.7285 - accuracy: 0.5550 - mae: 0.4976 - mse: 0.2478\n",
      "Validation Accuracy: 55.50%\n",
      "Validation MAE: 0.4976\n",
      "Validation MSE:¬†0.2478\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "loss, accuracy, mae, mse = model.evaluate(train_generator)\n",
    "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Validation MAE: {mae:.4f}\")\n",
    "print(f\"Validation MSE:¬†{mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dc1749f-563e-4090-b7e1-2050ae8cacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "Dog üê∂\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = image.load_img(r\"C:\\Users\\ASUS\\Downloads\\dog.webp\", target_size=(64,64))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "if prediction[0][0] > 0.5:\n",
    "    print(\"Dog üê∂\")\n",
    "else:\n",
    "    print(\"Cat üê±\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rafikdl)",
   "language": "python",
   "name": "rafikdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
